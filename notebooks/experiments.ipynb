{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import torch\n",
    "from pathlib import Path, PosixPath\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from scr.readers import *\n",
    "from scr.download_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = get_raw_documents(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepvk/USER-bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 512\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=' ', \n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=int(CHUNK_SIZE / 5),\n",
    "    strip_whitespace=True, \n",
    "    length_function=lambda x: len(tokenizer.encode(x, add_special_tokens=False))\n",
    ")\n",
    "\n",
    "chunked_documents_with_page_content = text_splitter.split_documents(raw_documents)\n",
    "print(len(chunked_documents_with_page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_text_splitters.character.RecursiveCharacterTextSplitter"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = [doc.page_content for doc in chunked_documents_with_page_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"using {device}\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"deepvk/USER-bge-m3\",\n",
    "    model_kwargs={'device': device})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_texts(chunked_documents, embedding_model, distance_strategy=DistanceStrategy.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(folder_path=\"../data/vector_dbs\", index_name=\"faiss_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_retrieve = 5\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": num_docs_retrieve})\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    chunked_documents_with_page_content)\n",
    "bm25_retriever.k = num_docs_retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_database = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_rerank = 3\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "compressor = CrossEncoderReranker(model=model, top_n=num_docs_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vector_database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = compression_retriever.invoke('революция')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(doc: Document) -> dict:\n",
    "    \"\"\"Редактирование документа, полученного из ретривера\n",
    "\n",
    "    Args:\n",
    "        doc (Document): документ из ретривера\n",
    "\n",
    "    Returns:\n",
    "        dict: словарь с содержанием 'содержание' и названием источника 'источник'\n",
    "    \"\"\"\n",
    "    page_content = doc.page_content\n",
    "    source = doc.metadata['source'].split(\"/\")[-1].split(\".\")[0]\n",
    "    return {'источник': source, 'содержание': page_content}\n",
    "\n",
    "def process_retrieve_output(docs: list[Document]) -> list[dict]:\n",
    "    \"\"\"Функция обработки документов из ретривера.\n",
    "\n",
    "    Args:\n",
    "        docs (list[Document]): документы из ретривера\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: обработанные документы\n",
    "    \"\"\"\n",
    "    processed_documents = []\n",
    "    for doc in docs:\n",
    "        processed_doc = process_data(doc)\n",
    "        processed_documents.append(processed_doc)\n",
    "    return processed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_documents = process_retrieve_output(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "museum_voice_assistant",
   "language": "python",
   "name": "museum_voice_assistant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
